{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:07:40.53142Z",
     "iopub.status.busy": "2022-06-05T21:07:40.531106Z",
     "iopub.status.idle": "2022-06-05T21:07:40.619322Z",
     "shell.execute_reply": "2022-06-05T21:07:40.618722Z",
     "shell.execute_reply.started": "2022-06-05T21:07:40.531353Z"
    },
    "papermill": {
     "duration": 0.122804,
     "end_time": "2022-05-12T10:15:14.04297",
     "exception": false,
     "start_time": "2022-05-12T10:15:13.920166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "from bisect import bisect\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "# BERT_PATH = \"../input/codebert-base/codebert-base\"\n",
    "BERT_PATH = \"microsoft/codebert-base\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:08:03.1527Z",
     "iopub.status.busy": "2022-06-05T21:08:03.152445Z",
     "iopub.status.idle": "2022-06-05T21:09:49.335203Z",
     "shell.execute_reply": "2022-06-05T21:09:49.334438Z",
     "shell.execute_reply.started": "2022-06-05T21:08:03.152671Z"
    },
    "papermill": {
     "duration": 82.291505,
     "end_time": "2022-05-12T10:16:36.365197",
     "exception": false,
     "start_time": "2022-05-12T10:15:14.073692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_train = 10000\n",
    "\n",
    "def read_notebook(path,id_name):\n",
    "    return (\n",
    "        pd.read_json(path, dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=id_name)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths = []\n",
    "directory = 'train'\n",
    "for file in os.scandir(directory):\n",
    "    if file.is_file():\n",
    "        paths.append(file.path)\n",
    "    if len(paths) == num_train:\n",
    "        break\n",
    "        \n",
    "id_names = []\n",
    "for name in paths:\n",
    "    name = name.split('/')\n",
    "    id_n = name[-1].split('.')\n",
    "    id_names.append(id_n[0])\n",
    "    \n",
    "# print(id_names)\n",
    "# print(paths)\n",
    "\n",
    "train_notebooks = []\n",
    "for i in range(len(paths)):\n",
    "    train_notebooks.append(read_notebook(paths[i],id_names[i]))\n",
    "    \n",
    "# print(train_notebooks[0])\n",
    "df = (\n",
    "    pd.concat(train_notebooks)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:09:49.337121Z",
     "iopub.status.busy": "2022-06-05T21:09:49.336868Z",
     "iopub.status.idle": "2022-06-05T21:09:55.140778Z",
     "shell.execute_reply": "2022-06-05T21:09:55.139876Z",
     "shell.execute_reply.started": "2022-06-05T21:09:49.337088Z"
    }
   },
   "outputs": [],
   "source": [
    "df_orders = pd.read_csv('train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()  # Split the string representation of cell_ids into a list\n",
    "\n",
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "#nb\n",
    "\n",
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "    how='right',\n",
    ")\n",
    "\n",
    "ranks = {}\n",
    "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(ranks, orient='index')\n",
    "    .rename_axis('id')\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index('cell_id', append=True)\n",
    ")\n",
    "\n",
    "#df_ranks\n",
    "\n",
    "df_ancestors = pd.read_csv('train_ancestors.csv', index_col='id')\n",
    "#df_ancestors\n",
    "\n",
    "df = df.reset_index().merge(df_ranks, on=[\"id\", \"cell_id\"]).merge(df_ancestors, on=[\"id\"])\n",
    "#df\n",
    "\n",
    "df[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "#df[\"pct_rank\"].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:11:34.21035Z",
     "iopub.status.busy": "2022-06-05T21:11:34.210086Z",
     "iopub.status.idle": "2022-06-05T21:11:35.467241Z",
     "shell.execute_reply": "2022-06-05T21:11:35.466493Z",
     "shell.execute_reply.started": "2022-06-05T21:11:34.21032Z"
    },
    "papermill": {
     "duration": 1.895199,
     "end_time": "2022-05-12T10:16:49.969199",
     "exception": false,
     "start_time": "2022-05-12T10:16:48.074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "siz = 0.1  # size of validation set\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=siz, random_state=0)\n",
    "\n",
    "train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "\n",
    "train_df = df.loc[train_ind].reset_index(drop=True)\n",
    "val_df = df.loc[val_ind].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:11:36.820136Z",
     "iopub.status.busy": "2022-06-05T21:11:36.819847Z",
     "iopub.status.idle": "2022-06-05T21:11:36.827933Z",
     "shell.execute_reply": "2022-06-05T21:11:36.82688Z",
     "shell.execute_reply.started": "2022-06-05T21:11:36.820104Z"
    },
    "papermill": {
     "duration": 0.262837,
     "end_time": "2022-05-12T10:16:51.011588",
     "exception": false,
     "start_time": "2022-05-12T10:16:50.748751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_inversions_slowly(ranks):\n",
    "    inversions = 0\n",
    "    size = len(ranks)\n",
    "    for i in range(size):\n",
    "        for j in range(i+1, size):\n",
    "            if ranks[i] > ranks[j]:\n",
    "                total += 1\n",
    "    return total\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:11:38.46607Z",
     "iopub.status.busy": "2022-06-05T21:11:38.465409Z",
     "iopub.status.idle": "2022-06-05T21:11:38.581292Z",
     "shell.execute_reply": "2022-06-05T21:11:38.580568Z",
     "shell.execute_reply.started": "2022-06-05T21:11:38.466032Z"
    },
    "papermill": {
     "duration": 0.371916,
     "end_time": "2022-05-12T10:16:52.797271",
     "exception": false,
     "start_time": "2022-05-12T10:16:52.425355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n",
    "\n",
    "val_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:11:39.573745Z",
     "iopub.status.busy": "2022-06-05T21:11:39.573481Z",
     "iopub.status.idle": "2022-06-05T21:11:39.597174Z",
     "shell.execute_reply": "2022-06-05T21:11:39.596546Z",
     "shell.execute_reply.started": "2022-06-05T21:11:39.573699Z"
    },
    "papermill": {
     "duration": 0.280778,
     "end_time": "2022-05-12T10:16:53.349877",
     "exception": false,
     "start_time": "2022-05-12T10:16:53.069099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(val_df_mark[\"pct_rank\"], np.ones(val_df_mark.shape[0])*train_df_mark[\"pct_rank\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:13:02.546566Z",
     "iopub.status.busy": "2022-06-05T21:13:02.546286Z",
     "iopub.status.idle": "2022-06-05T21:13:02.554541Z",
     "shell.execute_reply": "2022-06-05T21:13:02.553701Z",
     "shell.execute_reply.started": "2022-06-05T21:13:02.546536Z"
    },
    "papermill": {
     "duration": 7.145711,
     "end_time": "2022-05-12T10:17:00.757077",
     "exception": false,
     "start_time": "2022-05-12T10:16:53.611366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "# additional ref cell 8 of https://www.kaggle.com/code/heyytanay/ai4code-pytorch-training-codebert-w-b\n",
    "# 18 of https://www.kaggle.com/code/yuanzhezhou/ai4code-pairwise-bertsmall-inference\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.bert = transformers.RobertaModel.from_pretrained(BERT_PATH)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.top = nn.Linear(768, 1)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        x = self.bert(ids, mask)[0]\n",
    "        x = self.drop(x)\n",
    "        x = self.top(x[:, 0, :])\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:13:03.424228Z",
     "iopub.status.busy": "2022-06-05T21:13:03.423775Z",
     "iopub.status.idle": "2022-06-05T21:13:03.670945Z",
     "shell.execute_reply": "2022-06-05T21:13:03.670168Z",
     "shell.execute_reply.started": "2022-06-05T21:13:03.42419Z"
    },
    "papermill": {
     "duration": 0.474499,
     "end_time": "2022-05-12T10:17:01.487031",
     "exception": false,
     "start_time": "2022-05-12T10:17:01.012532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, max_len):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "\n",
    "        return ids, mask, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "train_ds = MarkdownDataset(train_df_mark, max_len=MAX_LEN)\n",
    "val_ds = MarkdownDataset(val_df_mark, max_len=MAX_LEN)\n",
    "\n",
    "#val_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:13:03.956665Z",
     "iopub.status.busy": "2022-06-05T21:13:03.956326Z",
     "iopub.status.idle": "2022-06-05T21:13:03.967254Z",
     "shell.execute_reply": "2022-06-05T21:13:03.966504Z",
     "shell.execute_reply.started": "2022-06-05T21:13:03.956633Z"
    },
    "papermill": {
     "duration": 0.265988,
     "end_time": "2022-05-12T10:17:02.580374",
     "exception": false,
     "start_time": "2022-05-12T10:17:02.314386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch < 1:\n",
    "        lr = 5e-5\n",
    "    elif epoch < 2:\n",
    "        lr = 1e-3\n",
    "    elif epoch < 5:\n",
    "        lr = 1e-4\n",
    "    else:\n",
    "        lr = 1e-5\n",
    "\n",
    "    for p in optimizer.param_groups:\n",
    "        p['lr'] = lr\n",
    "    return lr\n",
    "    \n",
    "def get_optimizer(net):\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n",
    "                                 eps=1e-08)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:13:04.975565Z",
     "iopub.status.busy": "2022-06-05T21:13:04.975095Z",
     "iopub.status.idle": "2022-06-05T21:13:04.981663Z",
     "shell.execute_reply": "2022-06-05T21:13:04.980939Z",
     "shell.execute_reply.started": "2022-06-05T21:13:04.975527Z"
    },
    "papermill": {
     "duration": 0.298424,
     "end_time": "2022-05-12T10:17:03.132",
     "exception": false,
     "start_time": "2022-05-12T10:17:02.833576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BS = 32\n",
    "NW = 2\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:13:06.820554Z",
     "iopub.status.busy": "2022-06-05T21:13:06.820297Z",
     "iopub.status.idle": "2022-06-05T21:42:57.474319Z",
     "shell.execute_reply": "2022-06-05T21:42:57.470698Z",
     "shell.execute_reply.started": "2022-06-05T21:13:06.820526Z"
    },
    "papermill": {
     "duration": 987.160977,
     "end_time": "2022-05-12T10:33:30.548236",
     "exception": false,
     "start_time": "2022-05-12T10:17:03.387259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def read_data(data):\n",
    "    return tuple(d for d in data[:-1]), data[-1]\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(inputs[0], inputs[1])\n",
    "\n",
    "            preds.append(pred.detach().numpy().ravel())\n",
    "            labels.append(target.detach().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs):\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    for e in range(epochs):   \n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "        \n",
    "        lr = adjust_lr(optimizer, e)\n",
    "        \n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs[0], inputs[1])\n",
    "\n",
    "            loss = criterion(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.detach().item())\n",
    "            preds.append(pred.detach().numpy().ravel())\n",
    "            labels.append(target.detach().numpy().ravel())\n",
    "            \n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
    "            \n",
    "        y_val, y_pred = validate(model, val_loader)\n",
    "            \n",
    "        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n",
    "        print()\n",
    "    return model, y_pred\n",
    "\n",
    "model = MarkdownModel()\n",
    "# model = model.cuda()\n",
    "model, y_pred = train(model, train_loader, val_loader, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that this is a particularly hot model, but I don't think it should go completely to waste either :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:42:57.477051Z",
     "iopub.status.busy": "2022-06-05T21:42:57.476604Z",
     "iopub.status.idle": "2022-06-05T21:42:58.351832Z",
     "shell.execute_reply": "2022-06-05T21:42:58.351043Z",
     "shell.execute_reply.started": "2022-06-05T21:42:57.477009Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'codebert-trained2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:42:58.353598Z",
     "iopub.status.busy": "2022-06-05T21:42:58.353342Z",
     "iopub.status.idle": "2022-06-05T21:42:58.428286Z",
     "shell.execute_reply": "2022-06-05T21:42:58.427642Z",
     "shell.execute_reply.started": "2022-06-05T21:42:58.35356Z"
    },
    "papermill": {
     "duration": 3.695855,
     "end_time": "2022-05-12T10:33:37.305989",
     "exception": false,
     "start_time": "2022-05-12T10:33:33.610134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the validation score.  This is going to be a bit lower than the Distilbert baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T21:48:11.338206Z",
     "iopub.status.busy": "2022-06-05T21:48:11.337714Z",
     "iopub.status.idle": "2022-06-05T21:48:11.503889Z",
     "shell.execute_reply": "2022-06-05T21:48:11.503047Z",
     "shell.execute_reply.started": "2022-06-05T21:48:11.338169Z"
    },
    "papermill": {
     "duration": 3.230655,
     "end_time": "2022-05-12T10:33:43.545936",
     "exception": false,
     "start_time": "2022-05-12T10:33:40.315281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "kendall_tau(df_orders.loc[y_dummy.index], y_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T15:12:46.01115Z",
     "iopub.status.busy": "2022-06-05T15:12:46.010828Z",
     "iopub.status.idle": "2022-06-05T15:12:46.080374Z",
     "shell.execute_reply": "2022-06-05T15:12:46.079344Z",
     "shell.execute_reply.started": "2022-06-05T15:12:46.011094Z"
    },
    "papermill": {
     "duration": 3.156008,
     "end_time": "2022-05-12T10:33:49.98707",
     "exception": false,
     "start_time": "2022-05-12T10:33:46.831062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "directory = 'test'\n",
    "for file in os.scandir(directory):\n",
    "    if file.is_file():\n",
    "        paths.append(file.path)\n",
    "    if len(paths) == num_train:\n",
    "        break\n",
    "        \n",
    "id_names = []\n",
    "for name in paths:\n",
    "    name = name.split('/')\n",
    "    id_n = name[-1].split('.')\n",
    "    id_names.append(id_n[0])\n",
    "    \n",
    "# print(id_names)\n",
    "# print(paths)\n",
    "\n",
    "test_notebooks = []\n",
    "for i in range(len(paths)):\n",
    "    test_notebooks.append(read_notebook(paths[i],id_names[i]))\n",
    "    \n",
    "# print(test_notebooks[0])\n",
    "\n",
    "test_df = (\n",
    "    pd.concat(test_notebooks)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T15:12:46.082599Z",
     "iopub.status.busy": "2022-06-05T15:12:46.081821Z",
     "iopub.status.idle": "2022-06-05T15:12:46.096274Z",
     "shell.execute_reply": "2022-06-05T15:12:46.095079Z",
     "shell.execute_reply.started": "2022-06-05T15:12:46.082559Z"
    },
    "papermill": {
     "duration": 3.580422,
     "end_time": "2022-05-12T10:33:56.648552",
     "exception": false,
     "start_time": "2022-05-12T10:33:53.06813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T15:12:46.098788Z",
     "iopub.status.busy": "2022-06-05T15:12:46.098333Z",
     "iopub.status.idle": "2022-06-05T15:12:46.226052Z",
     "shell.execute_reply": "2022-06-05T15:12:46.225042Z",
     "shell.execute_reply.started": "2022-06-05T15:12:46.098747Z"
    },
    "papermill": {
     "duration": 3.130783,
     "end_time": "2022-05-12T10:34:03.120038",
     "exception": false,
     "start_time": "2022-05-12T10:33:59.989255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[\"pct_rank\"] = 0\n",
    "test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), max_len=MAX_LEN)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=False)\n",
    "\n",
    "len(test_ds), test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T15:12:46.228282Z",
     "iopub.status.busy": "2022-06-05T15:12:46.227874Z",
     "iopub.status.idle": "2022-06-05T15:12:46.672914Z",
     "shell.execute_reply": "2022-06-05T15:12:46.671888Z",
     "shell.execute_reply.started": "2022-06-05T15:12:46.228252Z"
    },
    "papermill": {
     "duration": 4.00212,
     "end_time": "2022-05-12T10:34:10.223448",
     "exception": false,
     "start_time": "2022-05-12T10:34:06.221328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, y_test = validate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T15:12:46.675392Z",
     "iopub.status.busy": "2022-06-05T15:12:46.675061Z",
     "iopub.status.idle": "2022-06-05T15:12:46.685271Z",
     "shell.execute_reply": "2022-06-05T15:12:46.684167Z",
     "shell.execute_reply.started": "2022-06-05T15:12:46.675355Z"
    },
    "papermill": {
     "duration": 3.164567,
     "end_time": "2022-05-12T10:34:16.415308",
     "exception": false,
     "start_time": "2022-05-12T10:34:13.250741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T15:12:46.687112Z",
     "iopub.status.busy": "2022-06-05T15:12:46.686717Z",
     "iopub.status.idle": "2022-06-05T15:12:46.710162Z",
     "shell.execute_reply": "2022-06-05T15:12:46.709241Z",
     "shell.execute_reply.started": "2022-06-05T15:12:46.687068Z"
    },
    "papermill": {
     "duration": 3.093752,
     "end_time": "2022-05-12T10:34:22.827853",
     "exception": false,
     "start_time": "2022-05-12T10:34:19.734101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T15:12:46.714018Z",
     "iopub.status.busy": "2022-06-05T15:12:46.713603Z",
     "iopub.status.idle": "2022-06-05T15:12:46.723501Z",
     "shell.execute_reply": "2022-06-05T15:12:46.722314Z",
     "shell.execute_reply.started": "2022-06-05T15:12:46.713948Z"
    },
    "papermill": {
     "duration": 3.551878,
     "end_time": "2022-05-12T10:34:29.528868",
     "exception": false,
     "start_time": "2022-05-12T10:34:25.97699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T16:21:26.287796Z",
     "iopub.status.busy": "2022-06-05T16:21:26.28696Z",
     "iopub.status.idle": "2022-06-05T16:21:26.320842Z",
     "shell.execute_reply": "2022-06-05T16:21:26.319372Z",
     "shell.execute_reply.started": "2022-06-05T16:21:26.287698Z"
    }
   },
   "source": [
    "Now let's see how much memory was needed.  v2 *might* work on an 8GB GPU if you're not running anything else, but this version needs 16GB. :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
